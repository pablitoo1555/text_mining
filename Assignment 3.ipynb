{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bob Ross Continued\n",
    "## Attempting to predict season based on transcript\n",
    "#### Julian Furrow & Paul Kauffman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [T1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most EDA was done with last homework, but a quick transformation and look at the data again never hurts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 5)\n",
      "['Episode Name ', 'Season_#', 'Episode_#', 'snippet.title', 'transcript']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Name</th>\n",
       "      <th>Season_#</th>\n",
       "      <th>Episode_#</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Island in the Wilderness</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Island in the Wilderness (Season 29...</td>\n",
       "      <td>(mellow smooth jazz music) - Hello, I'm Bob Ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Episode Name   Season_#  Episode_#  \\\n",
       "0  Island in the Wilderness        29          1   \n",
       "\n",
       "                                       snippet.title  \\\n",
       "0  Bob Ross - Island in the Wilderness (Season 29...   \n",
       "\n",
       "                                          transcript  \n",
       "0  (mellow smooth jazz music) - Hello, I'm Bob Ro...  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Paul/Desktop/Rockhurst/BIA 6304-Text Mining/Homework 3/bob_ross_episodes_clean.csv')\n",
    "df = df.replace('/n', ' ', regex = True) #already considered and addressed in homework 2\n",
    "print(df.shape)\n",
    "print(list(df)) #headers, 'transcript' contains the episode text\n",
    "df.head(1) #looking at the first episode transcript to see how the text looks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing unneeded characters and replacing with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Island in the Wilderness</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Island in the Wilderness (Season 29...</td>\n",
       "      <td>(mellow smooth jazz music) - Hello, I'm Bob Ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Episode Name   Season  Episode  \\\n",
       "0  Island in the Wilderness      29        1   \n",
       "\n",
       "                                       snippet.title  \\\n",
       "0  Bob Ross - Island in the Wilderness (Season 29...   \n",
       "\n",
       "                                          transcript  \n",
       "0  (mellow smooth jazz music) - Hello, I'm Bob Ro...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace('_#','') \n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing NA value transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercasing all text in \"transcript\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Island in the Wilderness</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Island in the Wilderness (Season 29...</td>\n",
       "      <td>(mellow smooth jazz music) - hello, i'm bob ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mystic Mountain</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Mystic Mountain (Season 20 Episode 1)</td>\n",
       "      <td>(instrumental music) - hello, i'm bob ross, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain Lake Falls</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Bob Ross - Mountain Lake Falls (Season 29 Epis...</td>\n",
       "      <td>- hi, welcome back. certainly glad you could j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arctic Beauty</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Bob Ross - Arctic Beauty (Season 6 Episode 7)</td>\n",
       "      <td>- welcome back. awful glad you could join me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Walk in the Woods</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - A Walk in the Woods (Season 1 Episo...</td>\n",
       "      <td>- hi, i'm bob ross, and for the next 13\\nweeks...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Episode Name   Season  Episode  \\\n",
       "0  Island in the Wilderness      29        1   \n",
       "1           Mystic Mountain      20        1   \n",
       "2       Mountain Lake Falls      29        6   \n",
       "3             Arctic Beauty       6        7   \n",
       "4       A Walk in the Woods       1        1   \n",
       "\n",
       "                                       snippet.title  \\\n",
       "0  Bob Ross - Island in the Wilderness (Season 29...   \n",
       "1   Bob Ross - Mystic Mountain (Season 20 Episode 1)   \n",
       "2  Bob Ross - Mountain Lake Falls (Season 29 Epis...   \n",
       "3      Bob Ross - Arctic Beauty (Season 6 Episode 7)   \n",
       "4  Bob Ross - A Walk in the Woods (Season 1 Episo...   \n",
       "\n",
       "                                          transcript  \n",
       "0  (mellow smooth jazz music) - hello, i'm bob ro...  \n",
       "1  (instrumental music) - hello, i'm bob ross, an...  \n",
       "2  - hi, welcome back. certainly glad you could j...  \n",
       "3  - welcome back. awful glad you could join me t...  \n",
       "4  - hi, i'm bob ross, and for the next 13\\nweeks...  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transcript']= df['transcript'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Word Count by episode\n",
    "    looking to see if there is any difference in word count by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['transcript'].apply(lambda x : len(x.split())) #wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Island in the Wilderness</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Island in the Wilderness (Season 29...</td>\n",
       "      <td>(mellow smooth jazz music) - hello, i'm bob ro...</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mystic Mountain</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Mystic Mountain (Season 20 Episode 1)</td>\n",
       "      <td>(instrumental music) - hello, i'm bob ross, an...</td>\n",
       "      <td>4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain Lake Falls</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Bob Ross - Mountain Lake Falls (Season 29 Epis...</td>\n",
       "      <td>- hi, welcome back. certainly glad you could j...</td>\n",
       "      <td>3327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arctic Beauty</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Bob Ross - Arctic Beauty (Season 6 Episode 7)</td>\n",
       "      <td>- welcome back. awful glad you could join me t...</td>\n",
       "      <td>3431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Walk in the Woods</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - A Walk in the Woods (Season 1 Episo...</td>\n",
       "      <td>- hi, i'm bob ross, and for the next 13\\nweeks...</td>\n",
       "      <td>3137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Episode Name   Season  Episode  \\\n",
       "0  Island in the Wilderness      29        1   \n",
       "1           Mystic Mountain      20        1   \n",
       "2       Mountain Lake Falls      29        6   \n",
       "3             Arctic Beauty       6        7   \n",
       "4       A Walk in the Woods       1        1   \n",
       "\n",
       "                                       snippet.title  \\\n",
       "0  Bob Ross - Island in the Wilderness (Season 29...   \n",
       "1   Bob Ross - Mystic Mountain (Season 20 Episode 1)   \n",
       "2  Bob Ross - Mountain Lake Falls (Season 29 Epis...   \n",
       "3      Bob Ross - Arctic Beauty (Season 6 Episode 7)   \n",
       "4  Bob Ross - A Walk in the Woods (Season 1 Episo...   \n",
       "\n",
       "                                          transcript  word_count  \n",
       "0  (mellow smooth jazz music) - hello, i'm bob ro...        4060  \n",
       "1  (instrumental music) - hello, i'm bob ross, an...        4286  \n",
       "2  - hi, welcome back. certainly glad you could j...        3327  \n",
       "3  - welcome back. awful glad you could join me t...        3431  \n",
       "4  - hi, i'm bob ross, and for the next 13\\nweeks...        3137  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episodes by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "opacity": 0.9,
         "text": [
          13,
          13,
          10,
          10,
          13,
          13,
          1,
          3,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          8,
          13,
          13,
          13,
          13,
          13,
          11
         ],
         "textposition": "outside",
         "type": "bar",
         "uid": "1a869d66-c78a-11e8-97a9-44032c3fe26e",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          12,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          13,
          13,
          10,
          10,
          13,
          13,
          1,
          3,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          8,
          13,
          13,
          13,
          13,
          13,
          11
         ]
        }
       ],
       "layout": {
        "title": "Count of Episodes by Season",
        "xaxis": {
         "title": "Season"
        },
        "yaxis": {
         "title": "Episode Count"
        }
       }
      },
      "text/html": [
       "<div id=\"e3605b87-44d3-46f0-b7d7-3977d595786d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e3605b87-44d3-46f0-b7d7-3977d595786d\", [{\"opacity\": 0.9, \"text\": [13.0, 13.0, 10.0, 10.0, 13.0, 13.0, 1.0, 3.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 8.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0], \"textposition\": \"outside\", \"x\": [1, 2, 3, 4, 5, 6, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [13, 13, 10, 10, 13, 13, 1, 3, 12, 12, 13, 13, 13, 13, 13, 8, 13, 13, 13, 13, 13, 11], \"type\": \"bar\", \"uid\": \"1a869d66-c78a-11e8-97a9-44032c3fe26e\"}], {\"title\": \"Count of Episodes by Season\", \"xaxis\": {\"title\": \"Season\"}, \"yaxis\": {\"title\": \"Episode Count\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"e3605b87-44d3-46f0-b7d7-3977d595786d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e3605b87-44d3-46f0-b7d7-3977d595786d\", [{\"opacity\": 0.9, \"text\": [13.0, 13.0, 10.0, 10.0, 13.0, 13.0, 1.0, 3.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 8.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0], \"textposition\": \"outside\", \"x\": [1, 2, 3, 4, 5, 6, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [13, 13, 10, 10, 13, 13, 1, 3, 12, 12, 13, 13, 13, 13, 13, 8, 13, 13, 13, 13, 13, 11], \"type\": \"bar\", \"uid\": \"1a869d66-c78a-11e8-97a9-44032c3fe26e\"}], {\"title\": \"Count of Episodes by Season\", \"xaxis\": {\"title\": \"Season\"}, \"yaxis\": {\"title\": \"Episode Count\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_count = df.groupby(['Season'])[['Episode']].count()\n",
    "x = episode_count.index\n",
    "y = episode_count.Episode\n",
    "\n",
    "data = [go.Bar(x=x,\n",
    "            y=y,\n",
    "              text = y,\n",
    "               textposition = 'outside',\n",
    "              opacity =.9)]\n",
    "layout = go.Layout(\n",
    "                   title='Count of Episodes by Season',\n",
    "                   xaxis=dict(title='Season'),\n",
    "                   yaxis=dict( title='Episode Count'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig,filename='bar-direct-labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average wordcount by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "rgb(158,5,225)",
          "line": {
           "color": "rgb(10,48,107)",
           "width": 1.5
          }
         },
         "opacity": 0.9,
         "text": [
          2911,
          3152,
          3578,
          3634,
          3550,
          3703,
          3818,
          4564,
          4211,
          4240,
          4131,
          4103,
          4248,
          4184,
          4005,
          4232,
          3904,
          3882,
          3702,
          3705,
          3774,
          3686
         ],
         "textfont": {
          "color": "rgb(225,225,225)"
         },
         "textposition": "auto",
         "type": "bar",
         "uid": "1a94553a-c78a-11e8-8c6b-44032c3fe26e",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          12,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "y": [
          2911,
          3152,
          3578,
          3634,
          3550,
          3703,
          3818,
          4564,
          4211,
          4240,
          4131,
          4103,
          4248,
          4184,
          4005,
          4232,
          3904,
          3882,
          3702,
          3705,
          3774,
          3686
         ]
        }
       ],
       "layout": {
        "title": "Avg. Word Count by Season",
        "xaxis": {
         "title": "Season"
        },
        "yaxis": {
         "title": "Avg. Word Count"
        }
       }
      },
      "text/html": [
       "<div id=\"7c4c2447-e04f-4b44-8404-a1cecea2ab0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7c4c2447-e04f-4b44-8404-a1cecea2ab0a\", [{\"marker\": {\"color\": \"rgb(158,5,225)\", \"line\": {\"color\": \"rgb(10,48,107)\", \"width\": 1.5}}, \"opacity\": 0.9, \"text\": [2911.0, 3152.0, 3578.0, 3634.0, 3550.0, 3703.0, 3818.0, 4564.0, 4211.0, 4240.0, 4131.0, 4103.0, 4248.0, 4184.0, 4005.0, 4232.0, 3904.0, 3882.0, 3702.0, 3705.0, 3774.0, 3686.0], \"textfont\": {\"color\": \"rgb(225,225,225)\"}, \"textposition\": \"auto\", \"x\": [1, 2, 3, 4, 5, 6, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [2911.0, 3152.0, 3578.0, 3634.0, 3550.0, 3703.0, 3818.0, 4564.0, 4211.0, 4240.0, 4131.0, 4103.0, 4248.0, 4184.0, 4005.0, 4232.0, 3904.0, 3882.0, 3702.0, 3705.0, 3774.0, 3686.0], \"type\": \"bar\", \"uid\": \"1a94553a-c78a-11e8-8c6b-44032c3fe26e\"}], {\"title\": \"Avg. Word Count by Season\", \"xaxis\": {\"title\": \"Season\"}, \"yaxis\": {\"title\": \"Avg. Word Count\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7c4c2447-e04f-4b44-8404-a1cecea2ab0a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7c4c2447-e04f-4b44-8404-a1cecea2ab0a\", [{\"marker\": {\"color\": \"rgb(158,5,225)\", \"line\": {\"color\": \"rgb(10,48,107)\", \"width\": 1.5}}, \"opacity\": 0.9, \"text\": [2911.0, 3152.0, 3578.0, 3634.0, 3550.0, 3703.0, 3818.0, 4564.0, 4211.0, 4240.0, 4131.0, 4103.0, 4248.0, 4184.0, 4005.0, 4232.0, 3904.0, 3882.0, 3702.0, 3705.0, 3774.0, 3686.0], \"textfont\": {\"color\": \"rgb(225,225,225)\"}, \"textposition\": \"auto\", \"x\": [1, 2, 3, 4, 5, 6, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], \"y\": [2911.0, 3152.0, 3578.0, 3634.0, 3550.0, 3703.0, 3818.0, 4564.0, 4211.0, 4240.0, 4131.0, 4103.0, 4248.0, 4184.0, 4005.0, 4232.0, 3904.0, 3882.0, 3702.0, 3705.0, 3774.0, 3686.0], \"type\": \"bar\", \"uid\": \"1a94553a-c78a-11e8-8c6b-44032c3fe26e\"}], {\"title\": \"Avg. Word Count by Season\", \"xaxis\": {\"title\": \"Season\"}, \"yaxis\": {\"title\": \"Avg. Word Count\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "season_word_sum=  df.groupby(['Season'])[['word_count']].sum()\n",
    "season_avg = pd.DataFrame(round(season_word_sum['word_count']/episode_count['Episode']))\n",
    "season_avg.columns = ['Episode']\n",
    "\n",
    "x = season_avg.index\n",
    "y = season_avg.Episode\n",
    "\n",
    "data = [go.Bar(x=x,\n",
    "            y=y,\n",
    "              text = y,\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = 'rgb(225,225,225)'),\n",
    "                  marker=dict(\n",
    "        color='rgb(158,5,225)',\n",
    "        line=dict(\n",
    "            color='rgb(10,48,107)',\n",
    "            width=1.5,\n",
    "        )\n",
    "    ),              \n",
    "              opacity =.9)]\n",
    "layout = go.Layout(\n",
    "                   title='Avg. Word Count by Season',\n",
    "                   xaxis=dict(title='Season'),\n",
    "                   yaxis=dict( title='Avg. Word Count'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig,filename='bar-direct-labels')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because of the lack of episodes in season 12 & 17 the decision was made to remove these seasons because of a lack of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 6)\n",
      "(245, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "#dropping season 12 & 17\n",
    "df2 = df[(df.Season != 12) & (df.Season != 17)]\n",
    "#df2 = df2.drop(df2[df2.Season == 17].index, axis=0, inplace=True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953840"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_word_sum['word_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Name</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Island in the Wilderness</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Island in the Wilderness (Season 29...</td>\n",
       "      <td>(mellow smooth jazz music) - hello, i'm bob ro...</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mystic Mountain</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Mystic Mountain (Season 20 Episode 1)</td>\n",
       "      <td>(instrumental music) - hello, i'm bob ross, an...</td>\n",
       "      <td>4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain Lake Falls</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Bob Ross - Mountain Lake Falls (Season 29 Epis...</td>\n",
       "      <td>- hi, welcome back. certainly glad you could j...</td>\n",
       "      <td>3327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arctic Beauty</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Bob Ross - Arctic Beauty (Season 6 Episode 7)</td>\n",
       "      <td>- welcome back. awful glad you could join me t...</td>\n",
       "      <td>3431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Walk in the Woods</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - A Walk in the Woods (Season 1 Episo...</td>\n",
       "      <td>- hi, i'm bob ross, and for the next 13\\nweeks...</td>\n",
       "      <td>3137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Campfire</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Bob Ross - Campfire (Season 3 Episode 10)</td>\n",
       "      <td>- welcome back. glad to see ya today. you know...</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Valley View</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Valley View (Season 21 Episode 1)</td>\n",
       "      <td>(bright music) - hello, i'm bob ross and\\ni'd ...</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lazy River</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Bob Ross - Lazy River (Season 2 Episode 10)</td>\n",
       "      <td>- welcome back, glad to see you again. thought...</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fisherman's Trail</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Ross - Fisherman's Trail (Season 28 Episod...</td>\n",
       "      <td>(upbeat music) - hello i'm bob ross and i'd li...</td>\n",
       "      <td>3993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shades of Grey</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Bob Ross - Shades of Grey (Season 2 Episode 4)</td>\n",
       "      <td>- all right, here we\\nare ready to go again. y...</td>\n",
       "      <td>3234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Episode Name   Season  Episode  \\\n",
       "0   Island in the Wilderness      29        1   \n",
       "1            Mystic Mountain      20        1   \n",
       "2        Mountain Lake Falls      29        6   \n",
       "3              Arctic Beauty       6        7   \n",
       "4        A Walk in the Woods       1        1   \n",
       "6                   Campfire       3       10   \n",
       "7                Valley View      21        1   \n",
       "8                 Lazy River       2       10   \n",
       "9          Fisherman's Trail      28        1   \n",
       "11            Shades of Grey       2        4   \n",
       "\n",
       "                                        snippet.title  \\\n",
       "0   Bob Ross - Island in the Wilderness (Season 29...   \n",
       "1    Bob Ross - Mystic Mountain (Season 20 Episode 1)   \n",
       "2   Bob Ross - Mountain Lake Falls (Season 29 Epis...   \n",
       "3       Bob Ross - Arctic Beauty (Season 6 Episode 7)   \n",
       "4   Bob Ross - A Walk in the Woods (Season 1 Episo...   \n",
       "6           Bob Ross - Campfire (Season 3 Episode 10)   \n",
       "7        Bob Ross - Valley View (Season 21 Episode 1)   \n",
       "8         Bob Ross - Lazy River (Season 2 Episode 10)   \n",
       "9   Bob Ross - Fisherman's Trail (Season 28 Episod...   \n",
       "11     Bob Ross - Shades of Grey (Season 2 Episode 4)   \n",
       "\n",
       "                                           transcript  word_count  \n",
       "0   (mellow smooth jazz music) - hello, i'm bob ro...        4060  \n",
       "1   (instrumental music) - hello, i'm bob ross, an...        4286  \n",
       "2   - hi, welcome back. certainly glad you could j...        3327  \n",
       "3   - welcome back. awful glad you could join me t...        3431  \n",
       "4   - hi, i'm bob ross, and for the next 13\\nweeks...        3137  \n",
       "6   - welcome back. glad to see ya today. you know...        3250  \n",
       "7   (bright music) - hello, i'm bob ross and\\ni'd ...        4578  \n",
       "8   - welcome back, glad to see you again. thought...        2975  \n",
       "9   (upbeat music) - hello i'm bob ross and i'd li...        3993  \n",
       "11  - all right, here we\\nare ready to go again. y...        3234  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df2.shape)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating count and weighted vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 5334)\n",
      "(245, 5334)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words='english',\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.05,\n",
    "                     ngram_range = (1,2)) \n",
    "\n",
    "tfidf1 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= 'english', \n",
    "                        max_df=0.95, \n",
    "                        min_df=0.05,\n",
    "                        use_idf = True,\n",
    "                        ngram_range = (1,2))\n",
    "\n",
    "cv_dm = cv1.fit_transform(df2['transcript'])\n",
    "\n",
    "tfidf_dm = tfidf1.fit_transform(df2['transcript'])\n",
    "\n",
    "print(cv_dm.shape)\n",
    "print(tfidf_dm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y = df2['Season'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])\n",
    "\n",
    "\n",
    "X2 = tfidf_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X2), X2[0:10])\n",
    "\n",
    "\n",
    "y2 = df2['Season'].values #this is an array of labels\n",
    "#print(type(y2), y2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 5334)\n",
      "(13, 5334)\n",
      "(232,)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "# train and test on count\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 5334)\n",
      "(13, 5334)\n",
      "(232,)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "# train and test on weights\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X2_train.shape)\n",
    "print(X2_test.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "    & Cross Valadation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.23076923076923078\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.50      1.00      0.67         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.15      0.23      0.18        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree with count\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a Decision Tree dt_model_1 to the data\n",
    "dt_model_1 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model_1)\n",
    "dt_model_1.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = dt_model_1.predict(X_test)\n",
    "\n",
    "#print(dt_model_1.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model_1\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.25641026 0.18421053 0.27777778 0.17647059 0.24       0.35\n",
      " 0.2        0.2       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23560864359238973"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(dt_model_1, X_train, y_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.38461538461538464\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "         18       1.00      1.00      1.00         2\n",
      "         19       1.00      1.00      1.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       1.00      1.00      1.00         1\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.38      0.38      0.38        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree with weights\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a Decision Tree dt_model_2 to the data\n",
    "dt_model_2 = DecisionTreeClassifier(random_state = 42)\n",
    "#print(dt_model_2)\n",
    "dt_model_2.fit(X2_train, y2_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_eX2pected = y2_test\n",
    "clf2_predicted = dt_model_2.predict(X2_test)\n",
    "\n",
    "#print(dt_model_2.score(X2_test, y2_test))\n",
    "\n",
    "# summarize the fit of the dt_model_2\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_eX2pected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_eX2pected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.30769231 0.10526316 0.13888889 0.20588235 0.2        0.3\n",
      " 0.3        0.3       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23221583842713875"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(dt_model_2, X2_train, y2_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "    & Cross Valadation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.46153846153846156\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.50      1.00      0.67         1\n",
      "         18       1.00      0.50      0.67         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       1.00      1.00      1.00         1\n",
      "         27       0.50      1.00      0.67         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.42      0.46      0.41        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.46153846 0.47368421 0.36111111 0.61764706 0.68       0.65\n",
      " 0.5        0.55      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5367476052499273"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(lr_model, X_train, y_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.23076923076923078\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.50      1.00      0.67         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.50      1.00      0.67         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.23      0.15        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression lr_model2 to the data\n",
    "lr_model2 = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model2)\n",
    "lr_model2.fit(X2_train, y2_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y2_test\n",
    "clf3_predicted = lr_model2.predict(X2_test)\n",
    "\n",
    "#print(lr_model2.score(X2_test, y2_test))\n",
    "\n",
    "# summarize the fit of the lr_model2\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.30769231 0.36842105 0.22222222 0.32352941 0.44       0.45\n",
      " 0.3        0.35      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3452331242888519"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(lr_model2, X2_train, y2_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes \n",
    "    & Cross Valadation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.38461538461538464\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.50      1.00      0.67         1\n",
      "         18       1.00      0.50      0.67         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       1.00      1.00      1.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       1.00      1.00      1.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.38      0.38      0.36        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "nb_model = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "#print(nb_model)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf5_expected = y_test\n",
    "clf5_predicted = nb_model.predict(X_test)\n",
    "\n",
    "#print(nb_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the nb_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf5_expected, clf5_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf5_expected, clf5_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.43589744 0.47368421 0.30555556 0.35294118 0.56       0.75\n",
      " 0.3        0.5       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45975979730623695"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(nb_model, X_train, y_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "accuracy: \n",
      "0.15384615384615385\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       1.00      1.00      1.00         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.00      0.00      0.00         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.15      0.13        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "nb2_model = MultinomialNB()\n",
    "print(nb2_model)\n",
    "nb2_model.fit(X2_train, y2_train)\n",
    "\n",
    "# make predictions\n",
    "clf6_expected = y2_test\n",
    "clf6_predicted = nb2_model.predict(X2_test)\n",
    "\n",
    "#print(nb2_model.score(X2_test, y2_test))\n",
    "\n",
    "# summarize the fit of the nb2_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf6_expected, clf6_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf6_expected, clf6_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.28205128 0.28947368 0.22222222 0.32352941 0.4        0.3\n",
      " 0.15       0.25      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27715957503109206"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify NB2 with Cross Validation\n",
    "scores = cross_val_score(nb2_model, X2_train, y2_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(rf3_model, X3_train, y3_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [T2 ]\n",
    "\n",
    " ## trying to improve the predictions through PCA, New Vectors, and Custom Stop Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Weights Vectorization\n",
    "Minimize the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 1806)\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= 'english', \n",
    "                        max_df=0.9, \n",
    "                        min_df=0.15,\n",
    "                        use_idf = True,\n",
    "                        ngram_range = (1,2))\n",
    "\n",
    "tfidf_dm2 = tfidf2.fit_transform(df2['transcript'])\n",
    "\n",
    "print(tfidf_dm2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = tfidf_dm2.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "\n",
    "\n",
    "y3 = df2['Season'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Weight Vectorizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "\n",
    "# we want something that is smaller than 1800\n",
    "# let's start with 200 - that's about how big the second round space was\n",
    "# maybe we've kept more info for the same number of features\n",
    "#names = tfidf2.get_feature_names()\n",
    "\n",
    "for i in range(0,300, 10):\n",
    "\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca = pca.fit_transform(tfidf_dm2.toarray())\n",
    "    #print(\"Number of components: \" + str(i))\n",
    "    #print('PCA Total Variance Explained: ' + str(sum(pca.explained_variance_ratio_)))\n",
    "\n",
    "    # Decided to use 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Total Variance Explained: 0.8431531272943045\n"
     ]
    }
   ],
   "source": [
    "# 140 components from above was determined to be the most valuable combination\n",
    "pca = PCA(n_components=140)\n",
    "X_pca = pca.fit_transform(tfidf_dm2.toarray())\n",
    "\n",
    "print( 'PCA Total Variance Explained: ' + str(sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = X_pca  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X4), X4[0:10])\n",
    "\n",
    "\n",
    "y4 = df2['Season'].values #this is an array of labels\n",
    "#print(type(y4), y4[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 140)\n",
      "(13, 140)\n",
      "(232,)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "# train and test on count\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X4_train.shape)\n",
    "print(X4_test.shape)\n",
    "print(y4_train.shape)\n",
    "print(y4_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest using PCA variables derived from New Weighted Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.23076923076923078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      1.00      0.40         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "         18       1.00      0.50      0.67         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.50      1.00      0.67         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         25       0.00      0.00      0.00         0\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.21      0.23      0.18        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest using weights\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf4_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "#print(rf4_model)\n",
    "\n",
    "rf4_model.fit(X4_train, y4_train)\n",
    "\n",
    "rf4_expected = y4_test\n",
    "rf4_predicted = rf4_model.predict(X4_test)\n",
    "\n",
    "#print(rf4_model.score(X4_test,y4_test))\n",
    "\n",
    "# summarize the fit of the rf4_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(rf4_expected, rf4_predicted)))\n",
    "print(metrics.classification_report(rf4_expected, rf4_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.28205128 0.21052632 0.19444444 0.32352941 0.36       0.4\n",
      " 0.2        0.3       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2838189317562383"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(rf4_model, X4_train, y4_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression using PCA values derived from New Weighted Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.23076923076923078\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67         1\n",
      "          2       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.50      1.00      0.67         1\n",
      "         18       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         1\n",
      "         20       0.50      1.00      0.67         1\n",
      "         21       0.00      0.00      0.00         1\n",
      "         22       0.00      0.00      0.00         0\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         27       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         1\n",
      "         29       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.23      0.15        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression lr_model2 to the data\n",
    "lr_model3 = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model2)\n",
    "lr_model3.fit(X4_train, y4_train)\n",
    "\n",
    "# make predictions\n",
    "clf7_expected = y4_test\n",
    "clf7_predicted = lr_model3.predict(X4_test)\n",
    "\n",
    "#print(lr_model2.score(X2_test, y2_test))\n",
    "\n",
    "# summarize the fit of the lr_model2\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf7_expected, clf7_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf7_expected, clf7_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.38461538 0.34210526 0.22222222 0.41176471 0.52       0.35\n",
      " 0.4        0.3       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3663384469847318"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lr_model3, X4_train, y4_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom stopwords list - I choose to start with the nltk list\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_stopwords = stopwords.words(\"english\")\n",
    "#nltk_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "179\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(nltk_stopwords))\n",
    "print(len(nltk_stopwords))\n",
    "my_stopwords = nltk_stopwords + [\"trees\", \"mountain\", \"little\", \"little bit\", \"painting\", 'let', 'right', 'maybe', 'brush', \n",
    "                                 'like', 'want', 'color', 'paint', 'nice', 'll', 'don', 've', 'tree', 'mountains', 'bush',\n",
    "                                 'white']\n",
    "print(len(my_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Vectors using custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 1430)\n",
      "(245, 1430)\n"
     ]
    }
   ],
   "source": [
    "tfidf3 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= my_stopwords, \n",
    "                        max_df=0.9, \n",
    "                        min_df=0.15,\n",
    "                        use_idf = True,\n",
    "                        ngram_range = (1,2))\n",
    "\n",
    "tfidf_dm3 = tfidf3.fit_transform(df2['transcript'])\n",
    "\n",
    "cv2 = CountVectorizer(lowercase=True, \n",
    "                     stop_words= my_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.90, \n",
    "                     min_df=0.15,\n",
    "                     ngram_range = (1,2)) \n",
    "cv2_dm = cv2.fit_transform(df2['transcript'])\n",
    "\n",
    "print(tfidf_dm3.shape)\n",
    "print(cv2_dm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with newest weighted vector\n",
    "\n",
    "for i in range(0,300, 10):\n",
    "    \n",
    "    pca2 = PCA(n_components=i)\n",
    "    X_pca2 = pca2.fit_transform(tfidf_dm3.toarray())\n",
    "    #print(\"Number of components: \" + str(i))\n",
    "    #print('PCA Total Variance Explained: ' + str(sum(pca2.explained_variance_ratio_)))\n",
    "    # Decided to use 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Total Variance Explained: 0.9404247899500614\n"
     ]
    }
   ],
   "source": [
    "# 170 components from above was determined to be the most valuable combination\n",
    "pca4 = PCA(n_components=170)\n",
    "X_pca4 = pca4.fit_transform(cv2_dm.toarray())\n",
    "\n",
    "print( 'PCA Total Variance Explained: ' + str(sum(pca4.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with newest count vector\n",
    "\n",
    "for i in range(0,300, 10):\n",
    "    \n",
    "    pca3 = PCA(n_components=i)\n",
    "    X_pca3 = pca3.fit_transform(cv2_dm.toarray())\n",
    "    #print(\"Number of components: \" + str(i))\n",
    "    #print('PCA Total Variance Explained: ' + str(sum(pca3.explained_variance_ratio_)))\n",
    "    \n",
    "    # Decided to use 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Total Variance Explained: 0.8836610257324878\n"
     ]
    }
   ],
   "source": [
    "# 170 components from above was determined to be the most valuable combination\n",
    "pca3 = PCA(n_components=130)\n",
    "X_pca3 = pca3.fit_transform(cv2_dm.toarray())\n",
    "\n",
    "print( 'PCA Total Variance Explained: ' + str(sum(pca3.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we are trying to reduce the feature space we are going to use the PCA components derived from the count vector from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = X_pca3  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X4), X4[0:10])\n",
    "#print(X5.shape)\n",
    "\n",
    "y5 = df2['Season'].values #this is an array of labels\n",
    "#print(type(y4), y4[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 130)\n",
      "(13, 130)\n",
      "(232,)\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "# train and test on count\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.05, random_state=52) #random_state is set seed\n",
    "\n",
    "# function creates 5 output structures - order matters\n",
    "print(X5_train.shape)\n",
    "print(X5_test.shape)\n",
    "print(y5_train.shape)\n",
    "print(y5_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions using PCA derived from count vector using custom stop words.\n",
    "### Decision Tree then Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.15384615384615385\n",
      "===================\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         0\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.50      0.33      0.40         3\n",
      "         18       0.50      0.50      0.50         2\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         0\n",
      "         27       0.00      0.00      0.00         0\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.19      0.15      0.17        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree with PCA\n",
    "\n",
    "# fit a Decision Tree dt_model_1 to the data\n",
    "dt_model_2 = DecisionTreeClassifier(random_state=42)\n",
    "#print(dt_model_1)\n",
    "dt_model_2.fit(X5_train, y5_train)\n",
    "\n",
    "# make predictions\n",
    "clf8_expected = y5_test\n",
    "clf8_predicted = dt_model_2.predict(X5_test)\n",
    "\n",
    "#print(dt_model_1.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model_1\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf8_expected, clf8_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf8_expected, clf8_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.07692307692307693\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.50      0.67         2\n",
      "          2       0.00      0.00      0.00         0\n",
      "          3       0.00      0.00      0.00         0\n",
      "          4       0.00      0.00      0.00         1\n",
      "          5       0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      0.00         3\n",
      "         18       0.00      0.00      0.00         2\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         1\n",
      "         28       0.00      0.00      0.00         0\n",
      "         29       0.00      0.00      0.00         0\n",
      "         31       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.15      0.08      0.10        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest using weights\n",
    "rf5_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#print(rf5_model)\n",
    "\n",
    "rf5_model.fit(X5_train, y5_train)\n",
    "\n",
    "rf5_expected = y5_test\n",
    "rf5_predicted = rf5_model.predict(X5_test)\n",
    "\n",
    "#print(rf5_model.score(X4_test,y4_test))\n",
    "\n",
    "# summarize the fit of the rf5_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(rf5_expected, rf5_predicted)))\n",
    "print(metrics.classification_report(rf5_expected, rf5_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [T3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 693904.000\n",
      "Iteration  1, inertia 419453.441\n",
      "Iteration  2, inertia 415062.441\n",
      "Iteration  3, inertia 414076.725\n",
      "Iteration  4, inertia 413527.773\n",
      "Iteration  5, inertia 413278.544\n",
      "Iteration  6, inertia 413148.070\n",
      "Converged at iteration 6: center shift 0.000000e+00 within tolerance 1.497819e-04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "My_k = 13\n",
    "km = KMeans(n_clusters= My_k, init='k-means++', max_iter=100, n_init=1, random_state = 42,\n",
    "                verbose=True)\n",
    "km.fit(cv2_dm)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Episode  Cluster\n",
       "0       29        1        1\n",
       "1       20        1        1\n",
       "2       29        6        8\n",
       "3        6        7        9\n",
       "4        1        1       12\n",
       "6        3       10       10\n",
       "7       21        1        1\n",
       "8        2       10       10\n",
       "9       28        1        0\n",
       "11       2        4       12"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add cluster to df2\n",
    "\n",
    "df2['Cluster'] = clusters\n",
    "df2[['Season', 'Episode', 'Cluster']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
