{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project : Classifying Prospects\n",
    "### Paul Kauffman & Julian Furrow\n",
    "Attempting to classify potential clients using policy types they underwrite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "#from plotly.offline import init_notebook_mode, iplot\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "#import plotly.plotly as py\n",
    "#from plotly import tools\n",
    "#import plotly\n",
    "#plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Reference Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_excel('C:/Users/paulka/Desktop/Final Project/Model Summary.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27971, 3)\n",
      "['ProgramEntityPlusId', 'CoverageTypes', 'ClientClassification']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProgramEntityPlusId</th>\n",
       "      <th>CoverageTypes</th>\n",
       "      <th>ClientClassification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISP00036</td>\n",
       "      <td>GENERAL LIABILITY, LIQUOR LIABILITY</td>\n",
       "      <td>Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AISP00060</td>\n",
       "      <td>TRUCK LIABILITY, AUTOMOBILE</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AISP00092</td>\n",
       "      <td>GENERAL LIABILITY, EXCESS LIABILITY</td>\n",
       "      <td>Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AISP00093</td>\n",
       "      <td>GENERAL LIABILITY</td>\n",
       "      <td>Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AISP00127</td>\n",
       "      <td>GENERAL LIABILITY, PROPERTY</td>\n",
       "      <td>Retail Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AISP00128</td>\n",
       "      <td>EMPLOYMENT PRACTICES LIABILITY, HIRED/NON-OWN...</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AISP00153</td>\n",
       "      <td>PROFESSIONAL LIABILITY, PROPERTY, PACKAGE</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AISP00164</td>\n",
       "      <td>PACKAGE, GEN. LIAB./PROF. LIAB.</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AISP00170</td>\n",
       "      <td>BUSINESS OWNERS, GEN. LIAB./PROF. LIAB., PROF...</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AISP00241</td>\n",
       "      <td>EMPLOYMENT PRACTICES LIABILITY, CARGO, PACKAG...</td>\n",
       "      <td>Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProgramEntityPlusId                                      CoverageTypes  \\\n",
       "0           AISP00036                GENERAL LIABILITY, LIQUOR LIABILITY   \n",
       "1           AISP00060                        TRUCK LIABILITY, AUTOMOBILE   \n",
       "2           AISP00092                GENERAL LIABILITY, EXCESS LIABILITY   \n",
       "3           AISP00093                                  GENERAL LIABILITY   \n",
       "4           AISP00127                        GENERAL LIABILITY, PROPERTY   \n",
       "5           AISP00128   EMPLOYMENT PRACTICES LIABILITY, HIRED/NON-OWN...   \n",
       "6           AISP00153          PROFESSIONAL LIABILITY, PROPERTY, PACKAGE   \n",
       "7           AISP00164                    PACKAGE, GEN. LIAB./PROF. LIAB.   \n",
       "8           AISP00170   BUSINESS OWNERS, GEN. LIAB./PROF. LIAB., PROF...   \n",
       "9           AISP00241   EMPLOYMENT PRACTICES LIABILITY, CARGO, PACKAG...   \n",
       "\n",
       "  ClientClassification  \n",
       "0             Services  \n",
       "1              General  \n",
       "2        Manufacturing  \n",
       "3             Services  \n",
       "4         Retail Trade  \n",
       "5              General  \n",
       "6          Real Estate  \n",
       "7              General  \n",
       "8              General  \n",
       "9             Services  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('C:/Users/Paul/Desktop/Rockhurst/BIA 6304-Text Mining/Final Project/PE Classification Data.xlsx')\n",
    "df = df.replace('/n', ' ', regex = True)\n",
    "print(df.shape) # Shape of the dataset\n",
    "print(list(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count of Client Classification Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProgramEntityPlusId</th>\n",
       "      <th>CoverageTypes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClientClassification</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>*Dummy Data</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture</th>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Construction</th>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>7889</td>\n",
       "      <td>7889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Government</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manufacturing</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mining</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Estate</th>\n",
       "      <td>4445</td>\n",
       "      <td>4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retail Trade</th>\n",
       "      <td>839</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Services</th>\n",
       "      <td>9607</td>\n",
       "      <td>9607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transportation</th>\n",
       "      <td>2653</td>\n",
       "      <td>2653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wholesale Trade</th>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ProgramEntityPlusId  CoverageTypes\n",
       "ClientClassification                                    \n",
       "*Dummy Data                             1              1\n",
       "Agriculture                           258            258\n",
       "Construction                         1969           1969\n",
       "General                              7889           7889\n",
       "Government                             49             49\n",
       "Manufacturing                         120            120\n",
       "Mining                                 74             74\n",
       "Real Estate                          4445           4445\n",
       "Retail Trade                          839            839\n",
       "Services                             9607           9607\n",
       "Transportation                       2653           2653\n",
       "Wholesale Trade                        67             67"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('ClientClassification').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Sklearn Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA, RandomizedPCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base CountVectorizor \n",
    "    using base vecotrizer to establish baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27971, 173)\n",
      "           count\n",
      "liability  23355\n",
      "general    21020\n",
      "package    17021\n",
      "property   14328\n",
      "auto       10453\n",
      "            count\n",
      "terrorism     344\n",
      "operators     331\n",
      "indemnity     317\n",
      "protection    317\n",
      "glass         314\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True, lowercase=True, max_df=1.0, max_features=None, \n",
    "                     min_df=1, ngram_range=(1,1), stop_words=None)\n",
    "\n",
    "cv_dm = cv.fit_transform(df['CoverageTypes'].values.astype('U'))\n",
    "print(cv_dm.shape)\n",
    "names = cv.get_feature_names()   \n",
    "count = np.sum(cv_dm.toarray(), axis = 0) \n",
    "count2 = count.tolist() \n",
    "count_df = pd.DataFrame(count2, index = names, columns = ['count']) \n",
    "print(count_df.sort_values(['count'], ascending = False)[0:100] .head())\n",
    "print(count_df.sort_values(['count'], ascending = False)[0:100] .tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# [Round 1]\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base models to see how well the models predict on the test data. Test/Train is at 95/5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27971, 173)\n",
      "(27971,)\n",
      "(26572, 173)\n",
      "(1399, 173)\n",
      "(26572,)\n",
      "(1399,)\n"
     ]
    }
   ],
   "source": [
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "y = df['ClientClassification'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])\n",
    "print(y.shape)\n",
    "\n",
    "# train and test on count\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "(40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.4045746962115797\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.22      0.12      0.16        16\n",
      "   Construction       0.19      0.14      0.16        94\n",
      "        General       0.34      0.43      0.38       408\n",
      "     Government       0.00      0.00      0.00         3\n",
      "  Manufacturing       0.00      0.00      0.00         5\n",
      "         Mining       0.00      0.00      0.00         1\n",
      "    Real Estate       0.40      0.47      0.43       200\n",
      "   Retail Trade       0.18      0.11      0.14        44\n",
      "       Services       0.50      0.43      0.46       472\n",
      " Transportation       0.58      0.47      0.52       154\n",
      "Wholesale Trade       0.00      0.00      0.00         2\n",
      "\n",
      "    avg / total       0.41      0.40      0.40      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Decision Tree dt_model to the data\n",
    "dt_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = dt_model.predict(X_test)\n",
    "\n",
    "#print(dt_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "(51%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.509649749821301\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.67      0.12      0.21        16\n",
      "   Construction       0.47      0.07      0.13        94\n",
      "        General       0.40      0.50      0.44       408\n",
      "     Government       0.00      0.00      0.00         3\n",
      "  Manufacturing       0.00      0.00      0.00         5\n",
      "         Mining       0.00      0.00      0.00         1\n",
      "    Real Estate       0.58      0.58      0.58       200\n",
      "   Retail Trade       0.57      0.09      0.16        44\n",
      "       Services       0.55      0.63      0.59       472\n",
      " Transportation       0.67      0.53      0.59       154\n",
      "Wholesale Trade       0.00      0.00      0.00         2\n",
      "\n",
      "    avg / total       0.52      0.51      0.49      1399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "(44%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.44388849177984274\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    *Dummy Data       0.00      0.00      0.00         0\n",
      "    Agriculture       0.30      0.19      0.23        16\n",
      "   Construction       0.22      0.16      0.19        94\n",
      "        General       0.35      0.50      0.41       408\n",
      "     Government       0.00      0.00      0.00         3\n",
      "  Manufacturing       0.00      0.00      0.00         5\n",
      "         Mining       0.00      0.00      0.00         1\n",
      "    Real Estate       0.58      0.48      0.53       200\n",
      "   Retail Trade       0.29      0.11      0.16        44\n",
      "       Services       0.54      0.46      0.50       472\n",
      " Transportation       0.58      0.51      0.54       154\n",
      "Wholesale Trade       0.00      0.00      0.00         2\n",
      "\n",
      "    avg / total       0.46      0.44      0.44      1399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Naive Bayes model to the data\n",
    "nb_model = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "#print(nb_model)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = nb_model.predict(X_test)\n",
    "\n",
    "#print(nb_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the nb_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "(48%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.4832022873481058\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.29      0.12      0.17        16\n",
      "   Construction       0.34      0.12      0.17        94\n",
      "        General       0.37      0.43      0.40       408\n",
      "     Government       0.00      0.00      0.00         3\n",
      "  Manufacturing       0.00      0.00      0.00         5\n",
      "         Mining       0.00      0.00      0.00         1\n",
      "    Real Estate       0.52      0.52      0.52       200\n",
      "   Retail Trade       0.28      0.11      0.16        44\n",
      "       Services       0.53      0.63      0.58       472\n",
      " Transportation       0.73      0.54      0.62       154\n",
      "Wholesale Trade       0.00      0.00      0.00         2\n",
      "\n",
      "    avg / total       0.48      0.48      0.47      1399\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "#print(rf_model)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "clf4_expected = y_test\n",
    "clf4_predicted = rf_model.predict(X_test)\n",
    "\n",
    "#print(rf_model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the rf_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf4_expected, clf4_predicted)))\n",
    "print(metrics.classification_report(clf4_expected, clf4_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also Tried \n",
    "- SVM (50%)\n",
    "- Boosting (51%)\n",
    "- Bagging\n",
    "- KNN\n",
    "- NN\n",
    "\n",
    "Logistic Regression was the best model at 51%. Random forest also showed promise, though LR was the quick to run model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# [Round 2]\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"General\" Classification is a \"catch-all\" for Agents that had trouble being classified. Genral could be creating noise for the other classe. We may look to use this model to improve on the classification of the \"General\" population.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing General to try and improve accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New DF without \"General\" Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27971, 3)\n",
      "(20081, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_drop_gen = df[(df.ClientClassification != 'General') & (df.ClientClassification != '*Dummy Data') ]\n",
    "print(df_drop_gen.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Vectorizer\n",
    "    adding in a weighted set to see if model preform differently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 171)\n"
     ]
    }
   ],
   "source": [
    "wv = TfidfVectorizer(binary=False, lowercase=True, max_df=1.0, max_features=None, \n",
    "                     min_df=1, ngram_range=(1,1), stop_words=None)\n",
    "\n",
    "\n",
    "wv_dm = wv.fit_transform(df_drop_gen['CoverageTypes'].values.astype('U'))\n",
    "print(wv_dm.shape)\n",
    "wv_df =pd.DataFrame(wv_dm.toarray(), columns=wv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 171)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=False, lowercase=True, max_df=1.0, max_features=None, \n",
    "                     min_df=1, ngram_range=(1,1), stop_words=None)\n",
    "\n",
    "cv_dm = cv.fit_transform(df_drop_gen['CoverageTypes'].values.astype('U'))\n",
    "print(cv_dm.shape)\n",
    "cv_df =pd.DataFrame(cv_dm.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split (Count) (95/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 171)\n",
      "(20081,)\n",
      "(19076, 171)\n",
      "(1005, 171)\n",
      "(19076,)\n",
      "(1005,)\n"
     ]
    }
   ],
   "source": [
    "X = cv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X), X[0:10])\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "y = df_drop_gen['ClientClassification'].values #this is an array of labels\n",
    "#print(type(y), y[0:10])\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "# train and test on count\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split (Weights) (95/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 171)\n",
      "(20081,)\n",
      "(19076, 171)\n",
      "(1005, 171)\n",
      "(19076,)\n",
      "(1005,)\n"
     ]
    }
   ],
   "source": [
    "X_w = wv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X_w), X_w[0:10])\n",
    "print(X_w.shape)\n",
    "\n",
    "\n",
    "y_w = df_drop_gen['ClientClassification'].values #this is an array of labels\n",
    "#print(type(y_w), y[0:10])\n",
    "print(y_w.shape)\n",
    "\n",
    "\n",
    "# train and test on count\n",
    "X_w_train, X_w_test, y_w_train, y_w_test = train_test_split(X_w, y_w, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_w_train.shape)\n",
    "print(X_w_test.shape)\n",
    "print(y_w_train.shape)\n",
    "print(y_w_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Count) \n",
    "(55%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.5572139303482587\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.16      0.15      0.16        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "         Mining       0.00      0.00      0.00         0\n",
      "    Real Estate       0.55      0.61      0.57       228\n",
      "   Retail Trade       0.32      0.18      0.23        39\n",
      "       Services       0.64      0.65      0.65       475\n",
      " Transportation       0.68      0.64      0.66       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.55      0.56      0.55      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Decision Tree dt_model to the data\n",
    "dt_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = dt_model.predict(X_test)\n",
    "\n",
    "#print(dt_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Weight) \n",
    "(56%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.5611940298507463\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.16      0.13      0.15        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.58      0.58      0.58       228\n",
      "   Retail Trade       0.27      0.18      0.22        39\n",
      "       Services       0.63      0.68      0.65       475\n",
      " Transportation       0.61      0.64      0.62       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.54      0.56      0.55      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Decision Tree dt_model to the data\n",
    "dt_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model)\n",
    "dt_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_w_test\n",
    "clf1_predicted = dt_model.predict(X_w_test)\n",
    "\n",
    "#print(dt_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Count)\n",
    "(66%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6626865671641791\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.32      0.09      0.14        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.72      0.67      0.69       228\n",
      "   Retail Trade       0.40      0.10      0.16        39\n",
      "       Services       0.64      0.87      0.74       475\n",
      " Transportation       0.81      0.64      0.71       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.62      0.66      0.62      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Weight)\n",
    "(65%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6587064676616915\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.41      0.28      0.33        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.74      0.62      0.67       228\n",
      "   Retail Trade       0.56      0.13      0.21        39\n",
      "       Services       0.65      0.84      0.73       475\n",
      " Transportation       0.73      0.63      0.67       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.64      0.66      0.63      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_w_test\n",
    "clf2_predicted = lr_model.predict(X_w_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Count)\n",
    "(62%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6238805970149254\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.17      0.08      0.11        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "         Mining       0.00      0.00      0.00         0\n",
      "    Real Estate       0.67      0.61      0.64       228\n",
      "   Retail Trade       0.38      0.21      0.27        39\n",
      "       Services       0.63      0.81      0.71       475\n",
      " Transportation       0.72      0.62      0.67       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.59      0.62      0.60      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "#print(rf_model)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "clf4_expected = y_test\n",
    "clf4_predicted = rf_model.predict(X_test)\n",
    "\n",
    "#print(rf_model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the rf_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf4_expected, clf4_predicted)))\n",
    "print(metrics.classification_report(clf4_expected, clf4_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Weight)\n",
    "(64%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6407960199004975\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.50      0.07      0.12        15\n",
      "   Construction       0.25      0.09      0.13        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "         Mining       0.00      0.00      0.00         0\n",
      "    Real Estate       0.71      0.63      0.67       228\n",
      "   Retail Trade       0.44      0.18      0.25        39\n",
      "       Services       0.63      0.83      0.72       475\n",
      " Transportation       0.75      0.63      0.68       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.61      0.64      0.61      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "#print(rf_model)\n",
    "\n",
    "rf_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "clf4_expected = y_w_test\n",
    "clf4_predicted = rf_model.predict(X_w_test)\n",
    "\n",
    "#print(rf_model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the rf_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf4_expected, clf4_predicted)))\n",
    "print(metrics.classification_report(clf4_expected, clf4_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the removal of General from the training set all models preformed much better. This is due, more then likely, to the removal of the noise that the General classification created. Logistic regression was still the best model at 66%. DT and RF did show improvement when the weighted tokens were used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# [Round 3]\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes:\n",
    "- Remove common policy types\n",
    "- Binary = True\n",
    "- Tonenizer(x.split(','))\n",
    "- 80/20 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tonenizer(x.split(','))\n",
    "#### This will isolate specific policy types by splitting each token between commas. This will help reduce the feature space to see if this helps provie lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 130)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(binary=True, lowercase=True, max_df=1.0, max_features=None, \n",
    "                     min_df=1, ngram_range=(1,1), tokenizer=lambda x: x.split(','))\n",
    "\n",
    "cv_dm = cv.fit_transform(df_drop_gen['CoverageTypes'].values.astype('U'))\n",
    "print(cv_dm.shape)\n",
    "names = cv.get_feature_names()   \n",
    "count = np.sum(cv_dm.toarray(), axis = 0) \n",
    "count2 = count.tolist() \n",
    "count_df = pd.DataFrame(count2, index = names, columns = ['count']) \n",
    "#count_df.sort_values(['count'], ascending = False)[0:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_df.sort_values(['count'], ascending = False)[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 130)\n"
     ]
    }
   ],
   "source": [
    "wv = TfidfVectorizer(binary=True, lowercase=True, max_df=1.0, max_features=None, \n",
    "                     min_df=1, ngram_range=(1,1), tokenizer=lambda x: x.split(','))\n",
    "\n",
    "wv_dm = wv.fit_transform(df_drop_gen['CoverageTypes'].values.astype('U'))\n",
    "print(wv_dm.shape)\n",
    "names = wv.get_feature_names()   \n",
    "count = np.sum(wv_dm.toarray(), axis = 0) \n",
    "count2 = count.tolist() \n",
    "count_df = pd.DataFrame(count2, index = names, columns = ['count']) \n",
    "#count_df.sort_values(['count'], ascending = False)[0:100] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split (Counts) (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 130)\n",
      "(20081,)\n",
      "(19076, 130)\n",
      "(1005, 130)\n",
      "(19076,)\n",
      "(1005,)\n"
     ]
    }
   ],
   "source": [
    "X = cv_dm.toarray() \n",
    "#print(type(X), X[0:10])\n",
    "print(X.shape)\n",
    "\n",
    "y = df_drop_gen['ClientClassification'].values\n",
    "#print(type(y), y[0:10])\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split (Weights) (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 130)\n",
      "(20081,)\n",
      "(19076, 130)\n",
      "(1005, 130)\n",
      "(19076,)\n",
      "(1005,)\n"
     ]
    }
   ],
   "source": [
    "X_w = wv_dm.toarray()  #remember this is the output from the vectorizer and we are turning it into an array\n",
    "#print(type(X_w), X_w[0:10])\n",
    "print(X_w.shape)\n",
    "\n",
    "\n",
    "y_w = df_drop_gen['ClientClassification'].values #this is an array of labels\n",
    "#print(type(y_w), y[0:10])\n",
    "print(y_w.shape)\n",
    "\n",
    "\n",
    "# train and test on count\n",
    "X_w_train, X_w_test, y_w_train, y_w_test = train_test_split(X_w, y_w, test_size=0.05, random_state=42) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print(X_w_train.shape)\n",
    "print(X_w_test.shape)\n",
    "print(y_w_train.shape)\n",
    "print(y_w_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Count) \n",
    "(55%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.5492537313432836\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.16      0.16      0.16        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.57      0.60      0.59       228\n",
      "   Retail Trade       0.24      0.18      0.21        39\n",
      "       Services       0.64      0.65      0.65       475\n",
      " Transportation       0.60      0.58      0.59       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.54      0.55      0.54      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Decision Tree dt_model to the data\n",
    "dt_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = dt_model.predict(X_test)\n",
    "\n",
    "#print(dt_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Weights) \n",
    "(55%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.5830845771144278\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.21      0.17      0.19        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "         Mining       0.00      0.00      0.00         0\n",
      "    Real Estate       0.62      0.64      0.63       228\n",
      "   Retail Trade       0.24      0.21      0.22        39\n",
      "       Services       0.65      0.70      0.67       475\n",
      " Transportation       0.65      0.59      0.62       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.57      0.58      0.57      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a Decision Tree dt_model to the data\n",
    "dt_model = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "            splitter='best')\n",
    "#print(dt_model)\n",
    "dt_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_w_test\n",
    "clf1_predicted = dt_model.predict(X_w_test)\n",
    "\n",
    "#print(dt_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the dt_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Count) \n",
    "(66%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6666666666666666\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.32      0.09      0.14        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.73      0.67      0.70       228\n",
      "   Retail Trade       0.42      0.13      0.20        39\n",
      "       Services       0.64      0.87      0.74       475\n",
      " Transportation       0.81      0.63      0.71       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.63      0.67      0.63      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.62955211 0.62756598 0.63689727 0.64807047 0.63785145 0.62903903\n",
      " 0.62819975 0.63853904]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6344643882401912"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(lr_model, X_train, y_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (Weights) \n",
    "(66%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6656716417910448\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.42      0.29      0.34        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.74      0.66      0.69       228\n",
      "   Retail Trade       0.50      0.13      0.20        39\n",
      "       Services       0.66      0.83      0.74       475\n",
      " Transportation       0.74      0.64      0.69       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.64      0.67      0.64      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_w_test\n",
    "clf2_predicted = lr_model.predict(X_w_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.62955211 0.62756598 0.63689727 0.64807047 0.63785145 0.62903903\n",
      " 0.62819975 0.63853904]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6344643882401912"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lr_model, X_train, y_train, cv=8)\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Count) \n",
    "(63%%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6328358208955224\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.18      0.08      0.11        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.50      0.17      0.25         6\n",
      "         Mining       0.00      0.00      0.00         0\n",
      "    Real Estate       0.70      0.62      0.66       228\n",
      "   Retail Trade       0.37      0.18      0.24        39\n",
      "       Services       0.64      0.82      0.72       475\n",
      " Transportation       0.74      0.64      0.68       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.60      0.63      0.60      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap=True, class_weight= None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "#print(rf_model)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "clf4_expected = y_test\n",
    "clf4_predicted = rf_model.predict(X_test)\n",
    "\n",
    "#print(rf_model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the rf_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf4_expected, clf4_predicted)))\n",
    "print(metrics.classification_report(clf4_expected, clf4_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Weights) \n",
    "(65%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6447761194029851\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.20      0.07      0.11        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.73      0.62      0.67       228\n",
      "   Retail Trade       0.47      0.18      0.26        39\n",
      "       Services       0.63      0.86      0.73       475\n",
      " Transportation       0.75      0.61      0.67       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.61      0.64      0.61      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
    "            oob_score=True, random_state=42, verbose=1, warm_start=False)\n",
    "\n",
    "#print(rf_model)\n",
    "\n",
    "rf_model.fit(X_w_train, y_w_train)\n",
    "\n",
    "clf4_expected = y_w_test\n",
    "clf4_predicted = rf_model.predict(X_w_test)\n",
    "\n",
    "#print(rf_model.score(X_test,y_test))\n",
    "\n",
    "# summarize the fit of the rf_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf4_expected, clf4_predicted)))\n",
    "print(metrics.classification_report(clf4_expected, clf4_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the train/test split to 80/20 was done to make sure overfitting was not taking place. Additonally, cross validaiton was ran on Logistic Regression to check for overiftting. Results show that overfitting is mot likely not happening. Results were consistent with LR performing the best and quickest to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# [Round 4]\n",
    "## ---------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "    using \"OVR\" (one versus rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6656716417910448\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.32      0.09      0.14        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.73      0.67      0.70       228\n",
      "   Retail Trade       0.42      0.13      0.20        39\n",
      "       Services       0.64      0.87      0.74       475\n",
      " Transportation       0.80      0.63      0.70       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.63      0.67      0.63      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "    using \"Multinomial\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      "0.6567164179104478\n",
      "===================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Agriculture       0.00      0.00      0.00        15\n",
      "   Construction       0.34      0.11      0.17        98\n",
      "     Government       0.00      0.00      0.00         1\n",
      "  Manufacturing       0.00      0.00      0.00         6\n",
      "    Real Estate       0.71      0.64      0.67       228\n",
      "   Retail Trade       0.40      0.15      0.22        39\n",
      "       Services       0.64      0.86      0.73       475\n",
      " Transportation       0.79      0.64      0.70       140\n",
      "Wholesale Trade       0.00      0.00      0.00         3\n",
      "\n",
      "    avg / total       0.62      0.66      0.62      1005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression lr_model to the data\n",
    "lr_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='multinomial', n_jobs=1,\n",
    "          penalty='l1', random_state=None, solver='saga', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "#print(lr_model)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = lr_model.predict(X_test)\n",
    "\n",
    "#print(lr_model.score(X_test, y_test))\n",
    "\n",
    "# summarize the fit of the lr_model\n",
    "print(\"accuracy: \\n\" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print('===================')\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping Logistic Regression (running OVR and Multinomial with saga solver)\n",
    "  code borrowed from scikitlearn website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Dataset 20newsgroup, train_samples=19076, n_features=130, n_classes=10\n",
      "[model=One versus Rest, solver=saga] Number of epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paul\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model=One versus Rest, solver=saga] Number of epochs: 3\n",
      "[model=One versus Rest, solver=saga] Number of epochs: 7\n",
      "Test accuracy for model ovr: 0.6667\n",
      "% non-zero coefficients for model ovr, per class:\n",
      " [63.07692308 83.07692308 33.84615385 44.61538462 50.         93.07692308\n",
      " 66.92307692 93.07692308 93.07692308 36.15384615]\n",
      "Run time (7 epochs) for model ovr:6.21\n",
      "[model=Multinomial, solver=saga] Number of epochs: 1\n",
      "[model=Multinomial, solver=saga] Number of epochs: 3\n",
      "[model=Multinomial, solver=saga] Number of epochs: 7\n",
      "Test accuracy for model multinomial: 0.6587\n",
      "% non-zero coefficients for model multinomial, per class:\n",
      " [58.46153846 81.53846154 21.53846154 34.61538462 40.         90.76923077\n",
      " 60.76923077 90.76923077 90.76923077 24.61538462]\n",
      "Run time (7 epochs) for model multinomial:3.95\n",
      "Example run in 16.759 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22638e0b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(__doc__)\n",
    "# Author: Arthur Mensch\n",
    "\n",
    "t0 = time.clock()\n",
    "\n",
    "# We use SAGA solver\n",
    "solver = 'saga'\n",
    "\n",
    "# Turn down for faster run time\n",
    "n_samples = 10000\n",
    "\n",
    "# Memorized fetch_rcv1 for faster access\n",
    "#dataset = fetch_20newsgroups_vectorized('all')\n",
    "#X = dataset.data\n",
    "#y = dataset.target\n",
    "#X = X[:n_samples]\n",
    "#y = y[:n_samples]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    #random_state=42,\n",
    "                                                    #stratify=y,\n",
    "                                                    #test_size=0.1)\n",
    "train_samples, n_features = X_train.shape\n",
    "n_classes = np.unique(y).shape[0]\n",
    "\n",
    "print('Dataset 20newsgroup, train_samples=%i, n_features=%i, n_classes=%i'\n",
    "      % (train_samples, n_features, n_classes))\n",
    "\n",
    "models = {'ovr': {'name': 'One versus Rest', 'iters': [1, 3, 7]},\n",
    "          'multinomial': {'name': 'Multinomial', 'iters': [1, 3, 7]}}\n",
    "\n",
    "for model in models:\n",
    "    # Add initial chance-level values for plotting purpose\n",
    "    accuracies = [1 / n_classes]\n",
    "    times = [0]\n",
    "    densities = [1]\n",
    "\n",
    "    model_params = models[model]\n",
    "\n",
    "    # Small number of epochs for fast runtime\n",
    "    for this_max_iter in model_params['iters']:\n",
    "        print('[model=%s, solver=%s] Number of epochs: %s' %\n",
    "              (model_params['name'], solver, this_max_iter))\n",
    "        lr = LogisticRegression(solver=solver,\n",
    "                                multi_class=model,\n",
    "                                C=1,\n",
    "                                penalty='l1',\n",
    "                                fit_intercept=True,\n",
    "                                max_iter=this_max_iter,\n",
    "                                random_state=42,\n",
    "                                )\n",
    "        t1 = time.clock()\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_time = time.clock() - t1\n",
    "\n",
    "        y_pred = lr.predict(X_test)\n",
    "        accuracy = np.sum(y_pred == y_test) / y_test.shape[0]\n",
    "        density = np.mean(lr.coef_ != 0, axis=1) * 100\n",
    "        accuracies.append(accuracy)\n",
    "        densities.append(density)\n",
    "        times.append(train_time)\n",
    "    models[model]['times'] = times\n",
    "    models[model]['densities'] = densities\n",
    "    models[model]['accuracies'] = accuracies\n",
    "    print('Test accuracy for model %s: %.4f' % (model, accuracies[-1]))\n",
    "    print('%% non-zero coefficients for model %s, '\n",
    "          'per class:\\n %s' % (model, densities[-1]))\n",
    "    print('Run time (%i epochs) for model %s:'\n",
    "          '%.2f' % (model_params['iters'][-1], model, times[-1]))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for model in models:\n",
    "    name = models[model]['name']\n",
    "    times = models[model]['times']\n",
    "    accuracies = models[model]['accuracies']\n",
    "    ax.plot(times, accuracies, marker='o',\n",
    "            label='Model: %s' % name)\n",
    "    ax.set_xlabel('Train time (s)')\n",
    "    ax.set_ylabel('Test accuracy')\n",
    "ax.legend()\n",
    "fig.suptitle('Multinomial vs One-vs-Rest Logistic L1\\n'\n",
    "             'Dataset %s' % '20newsgroups')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.85)\n",
    "run_time = time.clock() - t0\n",
    "print('Example run in %.3f s' % run_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was an experiment to see if LR would work better with different multiclass settings. OVR was still the better of the two types. \n",
    "\n",
    "Moving forward we will look to run policy types we scrape from client websites through the model we chose. Logistic Regression will more then likely be the model of choice because of the accuracy of the model the speed it complete the task. Random Forest would also be considered but accuracy would need to improve and consideration would need to be made when speed of completion is deemed important.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
